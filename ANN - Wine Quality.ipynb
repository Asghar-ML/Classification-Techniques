{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality Type  \n",
       "0      9.4        5  red  \n",
       "1      9.8        5  red  \n",
       "2      9.8        5  red  \n",
       "3      9.8        6  red  \n",
       "4      9.4        5  red  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('CombinedWine.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4              0.70         0.00             1.9      0.076   \n",
       "1               7.8              0.88         0.00             2.6      0.098   \n",
       "2               7.8              0.76         0.04             2.3      0.092   \n",
       "3              11.2              0.28         0.56             1.9      0.075   \n",
       "4               7.4              0.70         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "6492            6.2              0.21         0.29             1.6      0.039   \n",
       "6493            6.6              0.32         0.36             8.0      0.047   \n",
       "6494            6.5              0.24         0.19             1.2      0.041   \n",
       "6495            5.5              0.29         0.30             1.1      0.022   \n",
       "6496            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "6492                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "6493                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "6494                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "6495                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "6496                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  Type  \n",
       "0         9.4        5     0  \n",
       "1         9.8        5     0  \n",
       "2         9.8        5     0  \n",
       "3         9.8        6     0  \n",
       "4         9.4        5     0  \n",
       "...       ...      ...   ...  \n",
       "6492     11.2        6     1  \n",
       "6493      9.6        5     1  \n",
       "6494      9.4        6     1  \n",
       "6495     12.8        7     1  \n",
       "6496     11.8        6     1  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "number = LabelEncoder()\n",
    "df[\"Type\"] = number.fit_transform(df[\"Type\"].astype(\"str\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4 ,  0.7 ,  0.  , ...,  9.4 ,  5.  ,  0.  ],\n",
       "       [ 7.8 ,  0.88,  0.  , ...,  9.8 ,  5.  ,  0.  ],\n",
       "       [ 7.8 ,  0.76,  0.04, ...,  9.8 ,  5.  ,  0.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  9.4 ,  6.  ,  1.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ..., 12.8 ,  7.  ,  1.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ..., 11.8 ,  6.  ,  1.  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Input and Output Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:12]\n",
    "Y = dataset[:,12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29752066, 0.41333333, 0.        , ..., 0.19101124, 0.20289855,\n",
       "        0.33333333],\n",
       "       [0.33057851, 0.53333333, 0.        , ..., 0.25842697, 0.26086957,\n",
       "        0.33333333],\n",
       "       [0.33057851, 0.45333333, 0.02409639, ..., 0.24157303, 0.26086957,\n",
       "        0.33333333],\n",
       "       ...,\n",
       "       [0.2231405 , 0.10666667, 0.11445783, ..., 0.13483146, 0.20289855,\n",
       "        0.5       ],\n",
       "       [0.14049587, 0.14      , 0.18072289, ..., 0.08988764, 0.69565217,\n",
       "        0.66666667],\n",
       "       [0.18181818, 0.08666667, 0.22891566, ..., 0.05617978, 0.55072464,\n",
       "        0.5       ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4547, 12) (975, 12) (975, 12) (4547,) (975,) (975,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(12,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4547 samples, validate on 975 samples\n",
      "Epoch 1/100\n",
      "4547/4547 [==============================] - 2s 539us/sample - loss: 0.6280 - accuracy: 0.7678 - val_loss: 0.5816 - val_accuracy: 0.7682\n",
      "Epoch 2/100\n",
      "4547/4547 [==============================] - 0s 85us/sample - loss: 0.5675 - accuracy: 0.7528 - val_loss: 0.5414 - val_accuracy: 0.7682\n",
      "Epoch 3/100\n",
      "4547/4547 [==============================] - 0s 85us/sample - loss: 0.5431 - accuracy: 0.7528 - val_loss: 0.5231 - val_accuracy: 0.7682\n",
      "Epoch 4/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.5294 - accuracy: 0.7528 - val_loss: 0.5098 - val_accuracy: 0.7682\n",
      "Epoch 5/100\n",
      "4547/4547 [==============================] - 0s 81us/sample - loss: 0.5165 - accuracy: 0.7528 - val_loss: 0.4969 - val_accuracy: 0.7682\n",
      "Epoch 6/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.5029 - accuracy: 0.7528 - val_loss: 0.4830 - val_accuracy: 0.7682\n",
      "Epoch 7/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.4872 - accuracy: 0.7528 - val_loss: 0.4669 - val_accuracy: 0.7682\n",
      "Epoch 8/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.4689 - accuracy: 0.7528 - val_loss: 0.4480 - val_accuracy: 0.7682\n",
      "Epoch 9/100\n",
      "4547/4547 [==============================] - 0s 84us/sample - loss: 0.4474 - accuracy: 0.7528 - val_loss: 0.4260 - val_accuracy: 0.7682\n",
      "Epoch 10/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.4231 - accuracy: 0.7550 - val_loss: 0.4019 - val_accuracy: 0.7805\n",
      "Epoch 11/100\n",
      "4547/4547 [==============================] - 0s 86us/sample - loss: 0.3960 - accuracy: 0.7730 - val_loss: 0.3746 - val_accuracy: 0.7990\n",
      "Epoch 12/100\n",
      "4547/4547 [==============================] - 0s 85us/sample - loss: 0.3669 - accuracy: 0.8087 - val_loss: 0.3461 - val_accuracy: 0.8338\n",
      "Epoch 13/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.3364 - accuracy: 0.8546 - val_loss: 0.3166 - val_accuracy: 0.8790\n",
      "Epoch 14/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.3055 - accuracy: 0.8942 - val_loss: 0.2870 - val_accuracy: 0.9077\n",
      "Epoch 15/100\n",
      "4547/4547 [==============================] - 0s 85us/sample - loss: 0.2752 - accuracy: 0.9228 - val_loss: 0.2583 - val_accuracy: 0.9313\n",
      "Epoch 16/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.2467 - accuracy: 0.9419 - val_loss: 0.2324 - val_accuracy: 0.9395\n",
      "Epoch 17/100\n",
      "4547/4547 [==============================] - 0s 81us/sample - loss: 0.2214 - accuracy: 0.9505 - val_loss: 0.2091 - val_accuracy: 0.9528\n",
      "Epoch 18/100\n",
      "4547/4547 [==============================] - 0s 78us/sample - loss: 0.1990 - accuracy: 0.9589 - val_loss: 0.1892 - val_accuracy: 0.9651\n",
      "Epoch 19/100\n",
      "4547/4547 [==============================] - 0s 84us/sample - loss: 0.1797 - accuracy: 0.9681 - val_loss: 0.1713 - val_accuracy: 0.9662\n",
      "Epoch 20/100\n",
      "4547/4547 [==============================] - 1s 120us/sample - loss: 0.1631 - accuracy: 0.9710 - val_loss: 0.1564 - val_accuracy: 0.9672\n",
      "Epoch 21/100\n",
      "4547/4547 [==============================] - 0s 106us/sample - loss: 0.1491 - accuracy: 0.9745 - val_loss: 0.1437 - val_accuracy: 0.9682\n",
      "Epoch 22/100\n",
      "4547/4547 [==============================] - 0s 84us/sample - loss: 0.1371 - accuracy: 0.9751 - val_loss: 0.1329 - val_accuracy: 0.9692\n",
      "Epoch 23/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.1269 - accuracy: 0.9780 - val_loss: 0.1237 - val_accuracy: 0.9744\n",
      "Epoch 24/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.1183 - accuracy: 0.9793 - val_loss: 0.1160 - val_accuracy: 0.9754\n",
      "Epoch 25/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.1109 - accuracy: 0.9795 - val_loss: 0.1093 - val_accuracy: 0.9754\n",
      "Epoch 26/100\n",
      "4547/4547 [==============================] - 0s 81us/sample - loss: 0.1046 - accuracy: 0.9806 - val_loss: 0.1038 - val_accuracy: 0.9754\n",
      "Epoch 27/100\n",
      "4547/4547 [==============================] - 0s 84us/sample - loss: 0.0991 - accuracy: 0.9813 - val_loss: 0.0985 - val_accuracy: 0.9764\n",
      "Epoch 28/100\n",
      "4547/4547 [==============================] - 0s 86us/sample - loss: 0.0944 - accuracy: 0.9811 - val_loss: 0.0942 - val_accuracy: 0.9774\n",
      "Epoch 29/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.0902 - accuracy: 0.9820 - val_loss: 0.0906 - val_accuracy: 0.9764\n",
      "Epoch 30/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.0865 - accuracy: 0.9815 - val_loss: 0.0871 - val_accuracy: 0.9774\n",
      "Epoch 31/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.0833 - accuracy: 0.9817 - val_loss: 0.0841 - val_accuracy: 0.9774\n",
      "Epoch 32/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.0804 - accuracy: 0.9822 - val_loss: 0.0815 - val_accuracy: 0.9774\n",
      "Epoch 33/100\n",
      "4547/4547 [==============================] - 0s 84us/sample - loss: 0.0778 - accuracy: 0.9820 - val_loss: 0.0792 - val_accuracy: 0.9785\n",
      "Epoch 34/100\n",
      "4547/4547 [==============================] - 0s 81us/sample - loss: 0.0755 - accuracy: 0.9826 - val_loss: 0.0772 - val_accuracy: 0.9805\n",
      "Epoch 35/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0734 - accuracy: 0.9835 - val_loss: 0.0752 - val_accuracy: 0.9785\n",
      "Epoch 36/100\n",
      "4547/4547 [==============================] - 0s 86us/sample - loss: 0.0715 - accuracy: 0.9839 - val_loss: 0.0735 - val_accuracy: 0.9815\n",
      "Epoch 37/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0697 - accuracy: 0.9833 - val_loss: 0.0720 - val_accuracy: 0.9815\n",
      "Epoch 38/100\n",
      "4547/4547 [==============================] - 0s 84us/sample - loss: 0.0682 - accuracy: 0.9844 - val_loss: 0.0707 - val_accuracy: 0.9774\n",
      "Epoch 39/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0668 - accuracy: 0.9844 - val_loss: 0.0693 - val_accuracy: 0.9815\n",
      "Epoch 40/100\n",
      "4547/4547 [==============================] - 0s 86us/sample - loss: 0.0654 - accuracy: 0.9842 - val_loss: 0.0681 - val_accuracy: 0.9815\n",
      "Epoch 41/100\n",
      "4547/4547 [==============================] - 0s 95us/sample - loss: 0.0641 - accuracy: 0.9850 - val_loss: 0.0672 - val_accuracy: 0.9795\n",
      "Epoch 42/100\n",
      "4547/4547 [==============================] - 0s 105us/sample - loss: 0.0631 - accuracy: 0.9848 - val_loss: 0.0661 - val_accuracy: 0.9805\n",
      "Epoch 43/100\n",
      "4547/4547 [==============================] - 1s 157us/sample - loss: 0.0619 - accuracy: 0.9846 - val_loss: 0.0653 - val_accuracy: 0.9805\n",
      "Epoch 44/100\n",
      "4547/4547 [==============================] - 1s 128us/sample - loss: 0.0610 - accuracy: 0.9850 - val_loss: 0.0643 - val_accuracy: 0.9815\n",
      "Epoch 45/100\n",
      "4547/4547 [==============================] - 1s 139us/sample - loss: 0.0600 - accuracy: 0.9850 - val_loss: 0.0638 - val_accuracy: 0.9805\n",
      "Epoch 46/100\n",
      "4547/4547 [==============================] - 0s 109us/sample - loss: 0.0592 - accuracy: 0.9857 - val_loss: 0.0628 - val_accuracy: 0.9805\n",
      "Epoch 47/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0583 - accuracy: 0.9857 - val_loss: 0.0621 - val_accuracy: 0.9805\n",
      "Epoch 48/100\n",
      "4547/4547 [==============================] - 0s 85us/sample - loss: 0.0576 - accuracy: 0.9855 - val_loss: 0.0615 - val_accuracy: 0.9805\n",
      "Epoch 49/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0569 - accuracy: 0.9861 - val_loss: 0.0609 - val_accuracy: 0.9805\n",
      "Epoch 50/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.0562 - accuracy: 0.9868 - val_loss: 0.0604 - val_accuracy: 0.9815\n",
      "Epoch 51/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0556 - accuracy: 0.9857 - val_loss: 0.0598 - val_accuracy: 0.9815\n",
      "Epoch 52/100\n",
      "4547/4547 [==============================] - 0s 89us/sample - loss: 0.0550 - accuracy: 0.9861 - val_loss: 0.0593 - val_accuracy: 0.9815\n",
      "Epoch 53/100\n",
      "4547/4547 [==============================] - 0s 84us/sample - loss: 0.0543 - accuracy: 0.9861 - val_loss: 0.0591 - val_accuracy: 0.9815\n",
      "Epoch 54/100\n",
      "4547/4547 [==============================] - 0s 84us/sample - loss: 0.0539 - accuracy: 0.9859 - val_loss: 0.0584 - val_accuracy: 0.9815\n",
      "Epoch 55/100\n",
      "4547/4547 [==============================] - 0s 81us/sample - loss: 0.0533 - accuracy: 0.9864 - val_loss: 0.0580 - val_accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "4547/4547 [==============================] - 0s 83us/sample - loss: 0.0528 - accuracy: 0.9866 - val_loss: 0.0576 - val_accuracy: 0.9826\n",
      "Epoch 57/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0523 - accuracy: 0.9870 - val_loss: 0.0574 - val_accuracy: 0.9826\n",
      "Epoch 58/100\n",
      "4547/4547 [==============================] - 0s 79us/sample - loss: 0.0518 - accuracy: 0.9859 - val_loss: 0.0569 - val_accuracy: 0.9826\n",
      "Epoch 59/100\n",
      "4547/4547 [==============================] - 0s 76us/sample - loss: 0.0514 - accuracy: 0.9870 - val_loss: 0.0567 - val_accuracy: 0.9836\n",
      "Epoch 60/100\n",
      "4547/4547 [==============================] - 0s 78us/sample - loss: 0.0510 - accuracy: 0.9870 - val_loss: 0.0567 - val_accuracy: 0.9826\n",
      "Epoch 61/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0505 - accuracy: 0.9868 - val_loss: 0.0567 - val_accuracy: 0.9836\n",
      "Epoch 62/100\n",
      "4547/4547 [==============================] - 0s 79us/sample - loss: 0.0502 - accuracy: 0.9868 - val_loss: 0.0559 - val_accuracy: 0.9836\n",
      "Epoch 63/100\n",
      "4547/4547 [==============================] - 0s 81us/sample - loss: 0.0499 - accuracy: 0.9875 - val_loss: 0.0554 - val_accuracy: 0.9836\n",
      "Epoch 64/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0496 - accuracy: 0.9866 - val_loss: 0.0552 - val_accuracy: 0.9836\n",
      "Epoch 65/100\n",
      "4547/4547 [==============================] - 0s 84us/sample - loss: 0.0491 - accuracy: 0.9879 - val_loss: 0.0551 - val_accuracy: 0.9836\n",
      "Epoch 66/100\n",
      "4547/4547 [==============================] - 0s 81us/sample - loss: 0.0489 - accuracy: 0.9872 - val_loss: 0.0549 - val_accuracy: 0.9836\n",
      "Epoch 67/100\n",
      "4547/4547 [==============================] - 0s 79us/sample - loss: 0.0485 - accuracy: 0.9877 - val_loss: 0.0545 - val_accuracy: 0.9836\n",
      "Epoch 68/100\n",
      "4547/4547 [==============================] - 0s 78us/sample - loss: 0.0482 - accuracy: 0.9879 - val_loss: 0.0543 - val_accuracy: 0.9836\n",
      "Epoch 69/100\n",
      "4547/4547 [==============================] - 0s 81us/sample - loss: 0.0479 - accuracy: 0.9877 - val_loss: 0.0541 - val_accuracy: 0.9836\n",
      "Epoch 70/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0476 - accuracy: 0.9881 - val_loss: 0.0539 - val_accuracy: 0.9826\n",
      "Epoch 71/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0474 - accuracy: 0.9879 - val_loss: 0.0537 - val_accuracy: 0.9826\n",
      "Epoch 72/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0470 - accuracy: 0.9883 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
      "Epoch 73/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0468 - accuracy: 0.9886 - val_loss: 0.0534 - val_accuracy: 0.9826\n",
      "Epoch 74/100\n",
      "4547/4547 [==============================] - 0s 79us/sample - loss: 0.0466 - accuracy: 0.9879 - val_loss: 0.0532 - val_accuracy: 0.9826\n",
      "Epoch 75/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0463 - accuracy: 0.9886 - val_loss: 0.0531 - val_accuracy: 0.9826\n",
      "Epoch 76/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0462 - accuracy: 0.9886 - val_loss: 0.0529 - val_accuracy: 0.9826\n",
      "Epoch 77/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0458 - accuracy: 0.9883 - val_loss: 0.0528 - val_accuracy: 0.9826\n",
      "Epoch 78/100\n",
      "4547/4547 [==============================] - 0s 79us/sample - loss: 0.0457 - accuracy: 0.9890 - val_loss: 0.0526 - val_accuracy: 0.9826\n",
      "Epoch 79/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0454 - accuracy: 0.9890 - val_loss: 0.0526 - val_accuracy: 0.9836\n",
      "Epoch 80/100\n",
      "4547/4547 [==============================] - 0s 79us/sample - loss: 0.0453 - accuracy: 0.9890 - val_loss: 0.0524 - val_accuracy: 0.9836\n",
      "Epoch 81/100\n",
      "4547/4547 [==============================] - 0s 85us/sample - loss: 0.0451 - accuracy: 0.9886 - val_loss: 0.0522 - val_accuracy: 0.9836\n",
      "Epoch 82/100\n",
      "4547/4547 [==============================] - 0s 79us/sample - loss: 0.0449 - accuracy: 0.9890 - val_loss: 0.0521 - val_accuracy: 0.9836\n",
      "Epoch 83/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0446 - accuracy: 0.9890 - val_loss: 0.0520 - val_accuracy: 0.9836\n",
      "Epoch 84/100\n",
      "4547/4547 [==============================] - 0s 81us/sample - loss: 0.0445 - accuracy: 0.9892 - val_loss: 0.0519 - val_accuracy: 0.9836\n",
      "Epoch 85/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0443 - accuracy: 0.9888 - val_loss: 0.0518 - val_accuracy: 0.9836\n",
      "Epoch 86/100\n",
      "4547/4547 [==============================] - 0s 78us/sample - loss: 0.0441 - accuracy: 0.9894 - val_loss: 0.0517 - val_accuracy: 0.9846\n",
      "Epoch 87/100\n",
      "4547/4547 [==============================] - 0s 81us/sample - loss: 0.0439 - accuracy: 0.9892 - val_loss: 0.0516 - val_accuracy: 0.9826\n",
      "Epoch 88/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0437 - accuracy: 0.9894 - val_loss: 0.0517 - val_accuracy: 0.9846\n",
      "Epoch 89/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0436 - accuracy: 0.9894 - val_loss: 0.0514 - val_accuracy: 0.9826\n",
      "Epoch 90/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0434 - accuracy: 0.9894 - val_loss: 0.0513 - val_accuracy: 0.9846\n",
      "Epoch 91/100\n",
      "4547/4547 [==============================] - 0s 102us/sample - loss: 0.0432 - accuracy: 0.9897 - val_loss: 0.0513 - val_accuracy: 0.9826\n",
      "Epoch 92/100\n",
      "4547/4547 [==============================] - 0s 104us/sample - loss: 0.0431 - accuracy: 0.9901 - val_loss: 0.0511 - val_accuracy: 0.9836\n",
      "Epoch 93/100\n",
      "4547/4547 [==============================] - 0s 106us/sample - loss: 0.0430 - accuracy: 0.9894 - val_loss: 0.0510 - val_accuracy: 0.9836\n",
      "Epoch 94/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0428 - accuracy: 0.9897 - val_loss: 0.0510 - val_accuracy: 0.9846\n",
      "Epoch 95/100\n",
      "4547/4547 [==============================] - 0s 79us/sample - loss: 0.0426 - accuracy: 0.9899 - val_loss: 0.0509 - val_accuracy: 0.9846\n",
      "Epoch 96/100\n",
      "4547/4547 [==============================] - 0s 82us/sample - loss: 0.0425 - accuracy: 0.9897 - val_loss: 0.0508 - val_accuracy: 0.9836\n",
      "Epoch 97/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0423 - accuracy: 0.9901 - val_loss: 0.0508 - val_accuracy: 0.9836\n",
      "Epoch 98/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0423 - accuracy: 0.9894 - val_loss: 0.0508 - val_accuracy: 0.9836\n",
      "Epoch 99/100\n",
      "4547/4547 [==============================] - 0s 80us/sample - loss: 0.0421 - accuracy: 0.9899 - val_loss: 0.0506 - val_accuracy: 0.9836\n",
      "Epoch 100/100\n",
      "4547/4547 [==============================] - 0s 81us/sample - loss: 0.0420 - accuracy: 0.9899 - val_loss: 0.0506 - val_accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=50, epochs=100,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "975/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 72us/sample - loss: 0.0444 - accuracy: 0.9836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.052478623875440694, 0.98358977]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[0.29752066 0.41333333 0.         0.01993865 0.11129568 0.03472222\n",
      " 0.06451613 0.20609215 0.6124031  0.19101124 0.20289855 0.33333333], Predicted=[0]\n"
     ]
    }
   ],
   "source": [
    "X1new = ([[7.4, 0.70, 0.00, 1.9, 0.076, 11.0, 34.0, 0.99780, 3.51, 0.56, 9.4, 5]])\n",
    "# scaling\n",
    "X1new = min_max_scaler.transform(X1new)\n",
    "# make a prediction\n",
    "ynew = model.predict_classes(X1new)\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X1new[0], ynew[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[0.18181818 0.08666667 0.22891566 0.00306748 0.01827243 0.07291667\n",
      " 0.21198157 0.04434162 0.41860465 0.05617978 0.55072464 0.5       ], Predicted=[1]\n"
     ]
    }
   ],
   "source": [
    "X2new = ([[6.0, 0.21, 0.38, 0.8, 0.020, 22.0, 98.0, 0.98941, 3.26, 0.32, 11.8, 6]])\n",
    "# scaling\n",
    "X2new = min_max_scaler.transform(X2new)\n",
    "# make a prediction\n",
    "ynew = model.predict_classes(X2new)\n",
    "\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X2new[0], ynew[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
